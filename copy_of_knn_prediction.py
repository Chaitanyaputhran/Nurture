# -*- coding: utf-8 -*-
"""Copy of KNN Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18k9cLYB5BnBAJzdxWTuV7RAXMKX8MRGf
"""
import pandas as pd
# Reading the data
health_data = pd.read_csv('/home/chaitanya/HackToFuture/Maternal Health Risk Data Set.csv')

# Import Libraries

import numpy as np  #Linear Algebra
import pandas as pd #Data Processing

from sklearn.preprocessing import LabelEncoder #One-Hot Encoding
from sklearn.model_selection import train_test_split 
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics

#Visualization and Plots
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import confusion_matrix

health_data

# Check few records
health_data.head()

# get to know about number of species (classes)
health_data['RiskLevel'].unique()

# if there is any NAN value
health_data.isnull().values.any()

# check the distribution of the class 
health_data['RiskLevel'].value_counts()







health_data.dtypes

for column in health_data.columns:
    if health_data[column].dtype == np.number:
        continue
health_data[column] = LabelEncoder().fit_transform(health_data[column])

sns.countplot(health_data['RiskLevel'])

health_data.head()

#seperating Features

X = health_data.drop(['RiskLevel'],axis = 1)
y = health_data['RiskLevel']

X

y

#Splitting Dataset into test and train

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)

#Selecting different Ks in range [1,12] and choose the one with high accuracy

k_range = list(range(1,12))
acc = []
for i in k_range:
    
    knn = KNeighborsClassifier(n_neighbors=i).fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    acc.append(metrics.accuracy_score(y_test, y_pred))

acc

knn = KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train)
y_pred = knn.predict(X_test)
print(y_pred)

#accuracy score
metrics.accuracy_score(y_test, y_pred)

#recall score
recall=metrics.recall_score(y_test,y_pred,average='macro')
print(recall)

#precision score
prec=metrics.precision_score(y_test,y_pred,average='macro')
print(prec)

#f1score
f1score = 2*((recall*prec)/(recall+prec))#verify mathematically
print(f1score)
f1score1 = metrics.f1_score(y_test,y_pred,average='macro')#verify functionally
print(f1score1)

con = confusion_matrix(y_test , knn.predict(X_test))
sns.heatmap(con, annot=True)
plt.tight_layout()
plt.show()
p,q,r,s ,t , u , v ,x,y= confusion_matrix(y_test ,knn.predict(X_test)).ravel()
           
tp = p
          
fn = q+r
fp =s+v
tn = t+u+x+y
tp = t
test_score = (tp+tn)/(tp+tn+fp+fn)
test_score

#ROC curve (receiver operating characteristic curve)



TPR = tp/(tp+fn)  #true postive rate
FPR = fp/(fp+tn)   #false positive rate
#AUC (area under the roc curve)
print(TPR)

print(FPR)

knn_prob = knn.predict_proba(X_test)

from sklearn.metrics import roc_auc_score

# auc scores
auc_score1 = roc_auc_score(y_test, knn_prob,multi_class='ovr')


print(auc_score1)

